# Text Chat Mode - ASK Conversation System

This document provides comprehensive documentation for the **Text Chat Mode** of the ASK conversation system. Text chat is the primary interaction mode where users communicate with an AI agent through typed messages.

## Table of Contents

1. [Overview](#overview)
2. [Architecture](#architecture)
3. [Component Structure](#component-structure)
4. [API Endpoints](#api-endpoints)
5. [Conversation Flow](#conversation-flow)
6. [Conversation Modes](#conversation-modes)
7. [Conversation Plans and Steps](#conversation-plans-and-steps)
8. [State Management](#state-management)
9. [Message Storage](#message-storage)
10. [Testing](#testing)

---

## Overview

The Text Chat Mode enables structured conversations between participants and an AI agent within ASK sessions. Key features include:

- **Real-time streaming responses** - AI responses are streamed to provide immediate feedback
- **Conversation plans** - Multi-step interview guides generated by AI
- **Step completion tracking** - Automatic detection of `STEP_COMPLETE` markers
- **Insight detection** - Automatic extraction of insights from conversations
- **Multiple conversation modes** - Support for individual, collaborative, and consultant modes
- **Thread isolation** - Message separation based on conversation mode

---

## Architecture

```
                    +-------------------+
                    |   ChatComponent   |
                    |  (Client-side)    |
                    +--------+----------+
                             |
              +--------------+--------------+
              |              |              |
              v              v              v
    +------------------+  +------------------+  +------------------+
    | GET /api/ask/[key]| | POST /api/ask/[key]| | POST /api/ask/[key]/stream |
    | (Load session)   | | (Send message)   | | (AI response)    |
    +------------------+  +------------------+  +------------------+
              |              |              |
              v              v              v
    +----------------------------------------------------------+
    |                    Supabase Database                      |
    |  - ask_sessions                                          |
    |  - messages                                              |
    |  - conversation_threads                                  |
    |  - ask_conversation_plans                                |
    |  - ask_conversation_plan_steps                           |
    |  - insights                                              |
    +----------------------------------------------------------+
```

### Key Components

| Component | Location | Purpose |
|-----------|----------|---------|
| `ChatComponent` | `src/components/chat/ChatComponent.tsx` | Main UI component |
| `GET /api/ask/[key]` | `src/app/api/ask/[key]/route.ts` | Load session and messages |
| `POST /api/ask/[key]` | `src/app/api/ask/[key]/route.ts` | Save user messages |
| `POST /api/ask/[key]/stream` | `src/app/api/ask/[key]/stream/route.ts` | Stream AI responses |
| `POST /api/ask/[key]/respond` | `src/app/api/ask/[key]/respond/route.ts` | Non-streaming AI response + insight detection |

---

## Component Structure

### ChatComponent (`src/components/chat/ChatComponent.tsx`)

The main chat interface component that handles:

- Message display with sender attribution
- Text input with keyboard shortcuts
- File upload support (images, audio, documents)
- Voice mode toggle (when enabled)
- Step completion celebration UI
- Agent typing indicator

#### Props Interface

```typescript
interface ChatComponentProps {
  askKey: string;
  ask: Ask | null;
  messages: Message[];
  conversationPlan?: ConversationPlan | null;
  onSendMessage: (content: string, type?: Message['type'], metadata?: Message['metadata']) => void;
  isLoading: boolean;
  onHumanTyping?: (isTyping: boolean) => void;
  currentParticipantName?: string | null;
  currentUserId?: string | null;
  isMultiUser?: boolean;
  showAgentTyping?: boolean;
  // Voice mode props
  voiceModeEnabled?: boolean;
  initialVoiceMode?: boolean;
  voiceModeSystemPrompt?: string;
  voiceModeUserPrompt?: string;
  voiceModePromptVariables?: Record<string, string | null | undefined>;
  voiceModeModelConfig?: { /* ... */ };
  onVoiceMessage?: (role: 'user' | 'agent', content: string, metadata?: { /* ... */ }) => void;
  onReplyBoxFocusChange?: (isFocused: boolean) => void;
  onVoiceModeChange?: (isActive: boolean) => void;
  // Message editing
  onEditMessage?: (messageId: string, newContent: string) => Promise<void>;
  // Consultant mode
  consultantMode?: boolean;
  onSpeakerChange?: (speaker: string) => void;
  // Timer props
  elapsedMinutes?: number;
  isTimerPaused?: boolean;
  onTogglePause?: () => void;
  expectedDurationMinutes?: number | null;
  onChatScroll?: (scrollTop: number, scrollDelta: number) => void;
}
```

### Message Interface

```typescript
interface Message {
  clientId?: string;           // Client-side stable ID for React keys
  id: string;                  // Database ID
  askKey: string;
  askSessionId?: string;
  conversationThreadId?: string | null;
  content: string;
  type: 'text' | 'audio' | 'image' | 'document';
  senderType: 'user' | 'ai' | 'system';
  senderId?: string | null;    // Profile ID of sender
  senderName?: string | null;
  timestamp: string;           // ISO string
  metadata?: {
    fileName?: string;
    fileSize?: number;
    mimeType?: string;
    duration?: number;
    senderName?: string;
    isInterim?: boolean;       // For streaming updates
    isEdited?: boolean;        // If message was edited
    [key: string]: unknown;
  };
}
```

### Internal Components

1. **MessageBubble** - Renders individual message with:
   - Sender attribution (name badge for multi-user)
   - Markdown rendering with syntax highlighting
   - Edit functionality for user messages
   - Step completion card display
   - Timestamp and edited indicator

2. **TypewriterText** - Handles text display:
   - Direct DOM updates for interim (streaming) messages to prevent flicker
   - ReactMarkdown for final messages with proper formatting

3. **FilePreview** - Shows selected files before sending

---

## API Endpoints

### GET /api/ask/[key]

**Purpose**: Load ASK session with messages, participants, insights, and conversation plan.

**Authentication**: Session cookie or `X-Invite-Token` header

**Response**:
```typescript
interface GetAskResponse {
  success: boolean;
  data: {
    ask: Ask;
    messages: Message[];
    insights: Insight[];
    challenges: Challenge[];
    conversationPlan?: ConversationPlan | null;
    conversationThreadId?: string | null;
    viewer?: {
      participantId: string;
      profileId?: string | null;
      isSpokesperson: boolean;
      name: string;
      email?: string | null;
      role?: string | null;
    } | null;
  };
}
```

**Key behaviors**:
- Creates initial AI welcome message if no messages exist
- Generates conversation plan if none exists
- Returns thread-specific messages based on conversation mode

**Example**:
```bash
curl -s 'http://localhost:3000/api/ask/my-ask-key' \
  -H 'Cookie: sb-access-token=...' | jq
```

---

### POST /api/ask/[key]

**Purpose**: Save a user message to the database.

**Request body**:
```typescript
{
  content: string;           // Required: message text
  type?: string;             // Optional: 'text' | 'audio' | 'image' | 'document'
  senderName: string;        // Required: display name of sender
  metadata?: object;         // Optional: additional data
  parentMessageId?: string;  // Optional: for threading
  timestamp?: string;        // Optional: ISO timestamp
}
```

**Response**:
```typescript
{
  success: boolean;
  data: {
    message: Message;
  };
  message?: string;
}
```

**Example**:
```bash
curl -s -X POST 'http://localhost:3000/api/ask/my-ask-key' \
  -H 'Content-Type: application/json' \
  -H 'X-Invite-Token: your-32-char-token' \
  -d '{
    "content": "Here is my response",
    "senderName": "John Doe"
  }'
```

---

### POST /api/ask/[key]/stream

**Purpose**: Get streaming AI response to user messages.

**Request body** (optional):
```typescript
{
  message?: string;  // New user message (if not already saved)
  content?: string;  // Alternative field for message content
}
```

**Response**: Server-Sent Events (SSE) stream

**Event types**:

| Event Type | Data | Description |
|------------|------|-------------|
| `chunk` | `{ type: 'chunk', content: string, done: boolean }` | Streaming text chunk |
| `message` | `{ type: 'message', message: Message }` | Final saved message |
| `step_completed` | `{ type: 'step_completed', conversationPlan: ConversationPlan, completedStepId: string }` | Step completion event |
| `insights` | `{ type: 'insights', insights: Insight[] }` | Detected insights |
| `done` | `{ type: 'done' }` | Stream complete |
| `error` | `{ type: 'error', error: string }` | Error occurred |

**Example**:
```bash
curl -N -X POST 'http://localhost:3000/api/ask/my-ask-key/stream' \
  -H 'Content-Type: application/json' \
  -H 'X-Invite-Token: your-32-char-token'
```

---

### POST /api/ask/[key]/respond

**Purpose**: Non-streaming AI response with insight detection.

**Request body**:
```typescript
{
  detectInsights?: boolean;     // If true, only run insight detection
  askSessionId?: string;        // Required when detectInsights=true
  mode?: 'insights-only';       // Skip AI response, only detect insights
  message?: string;             // For voice-generated messages
  metadata?: {
    voiceGenerated?: boolean;
    voiceTranscribed?: boolean;
  };
}
```

**Response**:
```typescript
{
  success: boolean;
  data: {
    message?: Message;          // AI response message
    insights: Insight[];        // Detected insights
    conversationPlan?: ConversationPlan;  // Updated plan if step completed
  };
}
```

---

### POST /api/ask/[key]/step-complete

**Purpose**: Manually complete a conversation step (used by voice mode).

**Request body**:
```typescript
{
  stepId: string;  // The step_identifier to complete (e.g., "step_1")
}
```

**Response**:
```typescript
{
  success: boolean;
  data: {
    conversationPlan: ConversationPlan;
    completedStepId: string;
    nextStepId: string | null;
  };
}
```

---

## Conversation Flow

### 1. Initial Load

```
User visits /ask/[key]
         |
         v
GET /api/ask/[key]
         |
         +---> Load ASK session from database
         |
         +---> Get or create conversation thread
         |
         +---> Load messages for thread
         |
         +---> Generate conversation plan (if not exists)
         |
         +---> Generate initial AI welcome message (if no messages)
         |
         v
Return session data to client
```

### 2. User Sends Message

```
User types and clicks Send
         |
         v
POST /api/ask/[key] (save user message)
         |
         v
POST /api/ask/[key]/stream (get AI response)
         |
         +---> Build conversation context
         |
         +---> Execute conversation agent
         |
         +---> Stream response chunks to client
         |
         +---> Save complete AI message
         |
         +---> Check for STEP_COMPLETE marker
         |         |
         |         +---> If found: complete step, activate next
         |         |
         |         +---> Send step_completed event
         |
         +---> Trigger insight detection
         |
         v
Send done event
```

### 3. Step Completion Detection

The AI agent includes `STEP_COMPLETE:step_id` markers in its responses when a conversation step is complete. The system detects these markers using:

```typescript
// From src/lib/sanitize.ts
function detectStepComplete(content: string): { hasMarker: boolean; stepId: string | null } {
  // Handles formats:
  // - STEP_COMPLETE:step_1
  // - STEP_COMPLETE: step_1 (with space)
  // - **STEP_COMPLETE:step_1** (markdown bold)
  // - STEP_COMPLETE: (no step_id - returns null, uses current step)
}
```

When detected:
1. The step is marked as `completed` in the database
2. The next step is activated (status = `active`)
3. An AI summary is generated asynchronously via `/api/ask/[key]/step-summary`
4. A `step_completed` event is sent to the client

---

## Conversation Modes

The `conversation_mode` field on `ask_sessions` determines thread isolation and message visibility:

### individual_parallel

- **Thread type**: Individual (one per user)
- **Isolation**: Complete - users only see their own messages
- **Use case**: Multiple people responding to the same questions independently

```typescript
// Each user gets their own thread
const thread = await getOrCreateConversationThread(
  supabase,
  askSessionId,
  profileId,        // User's profile ID
  { conversation_mode: 'individual_parallel' }
);
// thread.is_shared = false
// thread.user_id = profileId
```

### collaborative

- **Thread type**: Shared (single thread)
- **Isolation**: None - all participants see all messages
- **Use case**: Group brainstorming, team discussions

```typescript
// All users share the same thread
const thread = await getOrCreateConversationThread(
  supabase,
  askSessionId,
  null,             // No user-specific thread
  { conversation_mode: 'collaborative' }
);
// thread.is_shared = true
// thread.user_id = null
```

### group_reporter

- **Thread type**: Shared
- **Isolation**: None
- **Use case**: Group discussion with designated spokesperson
- **Special behavior**: One participant marked as `is_spokesperson` consolidates responses

### consultant

- **Thread type**: Shared
- **Isolation**: None
- **Use case**: AI listens to facilitate human-to-human conversations
- **Special behavior**:
  - AI does NOT auto-respond (no TTS in voice mode)
  - AI suggests questions to the facilitator
  - Speaker diarization identifies different speakers

---

## Conversation Plans and Steps

### Plan Structure

```typescript
interface ConversationPlan {
  id: string;
  conversation_thread_id: string;
  title: string | null;
  objective: string | null;
  total_steps: number;
  completed_steps: number;
  status: 'active' | 'completed' | 'abandoned';
  current_step_id: string | null;  // step_identifier (e.g., "step_1")
  plan_data: {
    steps: Array<{
      id: string;          // step_identifier
      title: string;
      objective: string;
      status: 'pending' | 'active' | 'completed' | 'skipped';
      summary?: string | null;
    }>;
  };
  created_at: string;
  updated_at: string;
}
```

### Step Lifecycle

```
1. Plan generated by ask-conversation-plan-generator agent
         |
         v
2. First step activated (status = 'active')
         |
         v
3. User engages in conversation
         |
         v
4. AI detects step objectives met
         |
         v
5. AI includes STEP_COMPLETE:step_id in response
         |
         v
6. System:
   - Marks step as 'completed'
   - Generates step summary asynchronously
   - Activates next step
         |
         v
7. Repeat until all steps completed
         |
         v
8. Celebration UI shown to user
```

### Plan Variables in Agent Prompts

The conversation agent receives these plan-related variables:

| Variable | Description |
|----------|-------------|
| `conversation_plan` | Full formatted plan with all steps |
| `current_step` | Current step title, objective, status |
| `current_step_id` | Step identifier (e.g., "step_1") |
| `completed_steps_summary` | Summaries of completed steps |
| `plan_progress` | Progress string (e.g., "2/5 etapes (40%)") |
| `is_last_step` | "true" if on final step |
| `all_steps_completed` | "true" if interview complete |
| `step_messages` | Messages from current step only |
| `step_messages_json` | JSON array of current step messages |

---

## State Management

### Client-Side State (React)

The chat component maintains local state for:

```typescript
// Input state
const [inputValue, setInputValue] = useState("");
const [selectedFiles, setSelectedFiles] = useState<FileUpload[]>([]);
const [isRecording, setIsRecording] = useState(false);

// UI state
const [isDragOver, setIsDragOver] = useState(false);
const [isVoiceMode, setIsVoiceMode] = useState(initialVoiceMode);

// Edit mode
const [editingMessageId, setEditingMessageId] = useState<string | null>(null);
const [editContent, setEditContent] = useState("");
const [isSubmittingEdit, setIsSubmittingEdit] = useState(false);
```

### Server-Side State (Database)

| Table | Purpose |
|-------|---------|
| `ask_sessions` | Session configuration and metadata |
| `ask_participants` | Users participating in session |
| `conversation_threads` | Thread isolation per conversation mode |
| `messages` | All chat messages |
| `ask_conversation_plans` | Interview plan metadata |
| `ask_conversation_plan_steps` | Individual step records |
| `insights` | Extracted insights from conversation |

### Real-Time Updates

Messages are stored immediately but the client typically uses optimistic updates:

1. User sends message -> Add to local state immediately
2. Server confirms -> Update with server-assigned ID
3. AI streams response -> Append chunks to display
4. AI finishes -> Replace interim message with final version

---

## Message Storage

### Insert User Message

```typescript
// Via RPC function to bypass RLS
const { data, error } = await supabase.rpc('insert_user_message', {
  p_ask_session_id: askSessionId,
  p_content: content,
  p_message_type: 'text',
  p_sender_type: 'user',
  p_metadata: { senderName: 'John' },
  p_created_at: new Date().toISOString(),
  p_user_id: profileId,
  p_parent_message_id: null,
  p_conversation_thread_id: threadId,
  p_plan_step_id: activeStepId,
});
```

### Insert AI Message

```typescript
// From src/lib/conversation-context.ts
const inserted = await insertAiMessage(
  supabase,
  askSessionId,
  conversationThreadId,
  content,
  'Agent',        // senderName
  planStepId      // Link to current step
);
```

### Message Retrieval

Messages are retrieved filtered by conversation thread:

```typescript
const { messages, error } = await getMessagesForThread(
  supabase,
  threadId
);
```

---

## Testing

### Test API Endpoints

```bash
# Load session
curl -s 'http://localhost:3000/api/ask/test-ask-key' | jq '.data.messages | length'

# Send message
curl -s -X POST 'http://localhost:3000/api/ask/test-ask-key' \
  -H 'Content-Type: application/json' \
  -d '{"content":"Test message","senderName":"Test User"}' | jq

# Trigger insight detection
curl -s -X POST 'http://localhost:3000/api/ask/test-ask-key/respond' \
  -H 'Content-Type: application/json' \
  -d '{"detectInsights":true,"askSessionId":"uuid-here"}' | jq '.data.insights'
```

### Verify Database State

```bash
# Check messages in a thread
source .env.local && PGGSSENCMODE=disable psql "$DATABASE_URL" -c "
SELECT id, sender_type, LEFT(content, 50) as content_preview,
       conversation_thread_id, plan_step_id
FROM messages
WHERE ask_session_id = (SELECT id FROM ask_sessions WHERE ask_key = 'test-key')
ORDER BY created_at DESC
LIMIT 10;
"

# Check conversation plan steps
source .env.local && PGGSSENCMODE=disable psql "$DATABASE_URL" -c "
SELECT step_identifier, title, status, completed_at
FROM ask_conversation_plan_steps
WHERE plan_id = (
  SELECT id FROM ask_conversation_plans
  WHERE conversation_thread_id = 'thread-uuid'
)
ORDER BY step_order;
"
```

### Unit Tests

Tests are located in `__tests__` directories:

- `src/lib/__tests__/asks.test.ts` - Thread management
- `src/lib/__tests__/sanitize.test.ts` - Step completion detection
- `src/lib/ai/__tests__/conversation-plan.test.ts` - Plan management

Run tests:
```bash
npm test -- --testPathPattern="sanitize"
npm test -- --testPathPattern="asks"
```

---

## Related Documentation

- [Voice Mode with ElevenLabs](/docs/features/voice-elevenlabs.md) - Voice chat implementation
- [Handlebars Templates](/docs/features/handlebars-templates.md) - Prompt variable system
- [AI System Architecture](/docs/ai-system/) - Agent configuration and execution
